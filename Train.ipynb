{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as fullfile\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Data loader\n",
    "\n",
    "train_path = fullfile('datasets', 'train')\n",
    "val_path = fullfile('datasets', 'val')\n",
    "test_path = fullfile('datasets', 'test')\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(0, 1)])\n",
    "val_test_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(0, 1)])\n",
    "\n",
    "train_dataset = ImageFolder(train_path, train_transform)\n",
    "val_dataset = ImageFolder(val_path, val_test_transform)\n",
    "test_dataset = ImageFolder(test_path, val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bacterial': 0, 'normal': 1, 'virus': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Model setting\n",
    "\n",
    "net = models.mobilenet_v2(pretrained=False)\n",
    "net.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "net.classifier[1] = nn.Linear(1280, 3, bias=True)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "# optimizer = optim.SGD(net.parameters(), lr = 0.005, momentum=0.9, weight_decay = 0.0001)\n",
    "\n",
    "scheduler_steplr = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "scheduler_reducelr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Train settings\n",
    "\n",
    "n_epoch = 20\n",
    "mini_batch_size = 64\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, path=fullfile('run', 'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Data loader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=mini_batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 1.227626).  Saving model ...\n",
      "epoch = 0, train loss = 0.8494431268085133, validation loss = 1.2276261821389198\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch = 1, train loss = 0.7020497918128967, validation loss = 1.5722232311964035\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch = 2, train loss = 0.6276898655024442, validation loss = 1.6557928621768951\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch = 3, train loss = 0.5546027530323375, validation loss = 1.816786840558052\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch = 4, train loss = 0.47412819212133234, validation loss = 2.027424693107605\n",
      "EarlyStopping counter: 5 out of 5\n",
      "epoch = 5, train loss = 0.36209767244078894, validation loss = 2.519050285220146\n",
      "EarlyStopping counter: 6 out of 5\n",
      "epoch = 6, train loss = 0.2526032342152162, validation loss = 2.448147814720869\n",
      "EarlyStopping counter: 7 out of 5\n",
      "epoch = 7, train loss = 0.13625753670930862, validation loss = 1.6542234271764755\n",
      "Validation loss decreased (1.227626 --> 1.203541).  Saving model ...\n",
      "epoch = 8, train loss = 0.1006488014351238, validation loss = 1.2035407274961472\n",
      "Validation loss decreased (1.203541 --> 1.184025).  Saving model ...\n",
      "epoch = 9, train loss = 0.044028120284730736, validation loss = 1.1840246468782425\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch = 10, train loss = 0.03693527677519755, validation loss = 1.2541816532611847\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch = 11, train loss = 0.03281909760765054, validation loss = 1.3069955110549927\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch = 12, train loss = 0.028827782296998936, validation loss = 1.2855371236801147\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch = 13, train loss = 0.02532996330410242, validation loss = 1.2839215844869614\n",
      "EarlyStopping counter: 5 out of 5\n",
      "epoch = 14, train loss = 0.0398501188240268, validation loss = 1.2746194154024124\n",
      "EarlyStopping counter: 6 out of 5\n",
      "epoch = 15, train loss = 0.03128899794749238, validation loss = 1.2817600816488266\n",
      "EarlyStopping counter: 7 out of 5\n",
      "epoch = 16, train loss = 0.014587528410960327, validation loss = 1.282377928495407\n",
      "EarlyStopping counter: 8 out of 5\n",
      "epoch = 17, train loss = 0.024145890450613064, validation loss = 1.315878540277481\n",
      "EarlyStopping counter: 9 out of 5\n",
      "epoch = 18, train loss = 0.019305724565955727, validation loss = 1.3001008331775665\n",
      "EarlyStopping counter: 10 out of 5\n",
      "epoch = 19, train loss = 0.02592025731097568, validation loss = 1.3165133595466614\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "def train_on_one_batch(net, data, criterion, device):\n",
    "    net.train()\n",
    "\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return net, loss\n",
    "\n",
    "\n",
    "def validate_on_epoch_end(net, val_loader, device, criterion):\n",
    "    val_batches_loss = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():                \n",
    "        for inputs_val, labels_val in val_loader:\n",
    "            inputs_val = inputs_val.to(device)\n",
    "            labels_val = labels_val.to(device)\n",
    "\n",
    "            outputs_val = net(inputs_val)\n",
    "            val_batch_loss = criterion(outputs_val, labels_val)\n",
    "            val_batches_loss.append(val_batch_loss.item())\n",
    "\n",
    "        return np.mean(val_batches_loss)\n",
    "        \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    # train\n",
    "    train_batches_loss = []\n",
    "    for i, data in enumerate(train_loader, start=0):        \n",
    "        net, train_batch_loss = train_on_one_batch(net, data, criterion, device)\n",
    "        train_batches_loss.append(train_batch_loss.item())\n",
    "    train_loss = np.mean(train_batches_loss)\n",
    "\n",
    "    # validation\n",
    "    val_loss = validate_on_epoch_end(net, val_loader, device, criterion)\n",
    "\n",
    "    print(f\"epoch = {epoch}, train loss = {train_loss}, validation loss = {val_loss}\")\n",
    "\n",
    "    early_stopping(val_loss, net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break    \n",
    "\n",
    "    # update learning rate\n",
    "    scheduler_steplr.step()\n",
    "\n",
    "\n",
    "print(\"Finished training\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ff9dde79ffbf809b6f08d722232c97431b152798e28a28866c57ce3683fd509"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Yolov5': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
